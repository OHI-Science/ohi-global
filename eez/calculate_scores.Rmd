---
title: "OHI `r format(Sys.Date(), '%Y')` - Calculate Scores"
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    toc: true
    number_sections: true
    theme: cerulean
    highlight: haddock
  pdf_document:
    toc: true
editor_options: 
  chunk_output_type: console
---

# Summary

This script calculates the OHI scores and is used after every layer is updated in the global prep.  

## Updates from previous assessment

v2022 - new `.Rmd`

# Methods  

## Steps outline

1. Download ohicore package  

2. Identify repo where data will be taken from 

3. Set scenario years in this year's assessment  

4. Set up the R environment  

5. Be sure to push all ohiprep changes!!  

6. Update the newest layer's file location and file name in metadata_documentation/layers_eez_base.csv  

7. Make sure the appropriate data year is entered in eez/conf/scenario_data_years.csv  

8. Run following to update the layers.csv file with the latest information in layers_eez_base.csv and to reset  

9. Run scenarios!  

10. Review results

11. Summarize results in an issue to update team members!

12. Update metadata files

## Steps 1-3 

**This should be edited once at the beginning of the assessment year**

### Step 1

Install the appropriate `ohicore` package. Options are:

- @master_a2015: used if assessment was done prior to 2016 and not updated

- @master: typically this version will be used

- @dev: used when testing new code in ohicore (used in v2022)

```{r setup, eval = FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, eval = FALSE, echo = TRUE)
if (!require(devtools)){install.packages("devtools")}
if (!require(ohicore)){devtools::install_github('ohi-science/ohicore@dev')}
```

### Step 2

Identify the repo where data will be taken from: 

```{r eval = FALSE}
current_year <- 2022
version_year <- paste0("v", current_year)
repo_loc <- paste0("https://raw.githubusercontent.com/OHI-Science/ohiprep_", version_year, "/gh-pages/")
```

### Step 3

Define the scenario years in this year's assessment

```{r eval = FALSE}
scenario_years <- c(2012:current_year)
```

## Steps 4-11 

**These are done as each data layer is updated.**

### Step 4

Set up the R environment 

```{r eval = FALSE}
## load packages:
if (!require(librarian)){install.packages("librarian")}
librarian::shelf(
  tidyverse,
  here,
  ohicore,
  plotly,
  zoo,
  htmlwidgets
) 

## source file path info depending on operating system
source(paste0('http://ohi-science.org/ohiprep_', version_year, '/workflow/R/common.R'))
```

**After updating a data layer**

### Step 5

Be sure to push all ohiprep changes!!

### Step 6

Update the newest layer's file location and file name in `metadata_documentation/layers_eez_base.csv` by running the function below and responding to the resulting prompts in the console  

```{r}
## run function and respond to prompts in console if layers_eez_base.csv needs to be updated
layers_eez_base_updater()
```


### Step 7

Make sure the appropriate data year is entered in `eez/conf/scenario_data_years.csv`

### Step 8

Run following to update the `layers.csv` file with the latest information in `layers_eez_base.csv`.

If more complex changes are made to layer (i.e. changes to layer names, removing/adding layers, etc) run the following scripts: 

- `eez_layers_meta_data/check_layer_harmony.R` 

  - to make sure that the layer names across all the metadata files are consistent, add information to the meta data files as necessary

- `eez_layers_meta_data/update_targets_with_pre_res.R` 

  - to update `eez_layers_meta_data/layers_eez_targets.csv` if layers are added to the resilience/pressures matrices in the `eez/con`f folder. 

```{r eval = FALSE}
source(here("metadata_documentation", "layers_eez_script.R"))
```

### Step 9

Run scenarios!

```{r eval = FALSE}
## Read in the layers.csv file with paths to the data files
g <- read.csv(here("eez/layers.csv"), stringsAsFactors = FALSE, na.strings='')

## establish locations of layers and save information
lyrs = g %>%
  dplyr::filter(ingest==TRUE) %>%
  dplyr::mutate(dir = gsub("ohiprep:", repo_loc, dir)) %>%
  dplyr::mutate(
    path_in        = file.path(dir, fn),
    #path_in_exists = file.exists(path_in),
    filename = sprintf('%s.csv', layer),
    path_out = sprintf(here('eez/layers/%s.csv'), layer)) %>%
  dplyr::select(
    targets, layer, name, description,
    fld_value=name_data_fld, units,
    path_in, filename, path_out, ingest) %>%  # path_in_exists
  dplyr::arrange(targets, layer)

# copy layers into layers folder
for (j in 1:nrow(lyrs)){ # j=4
  tmp <- read.csv(lyrs$path_in[j])
  write.csv(tmp, lyrs$path_out[j], row.names=FALSE)
}

# delete extraneous files
files_extra = setdiff(list.files('layers'), as.character(lyrs$filename))
unlink(sprintf('layers/%s', files_extra))

# layers registry (this includes files that are ingest=FALSE)
lyrs_reg = lyrs %>%
  dplyr::select(
    targets, ingest, layer, name, description,
    fld_value, units, filename)

write.csv(lyrs_reg, here('eez/layers.csv'), row.names=F, na='')

# Run check on layers
conf   = ohicore::Conf(here('eez/conf'))

ohicore::CheckLayers(layers.csv = here('eez/layers.csv'),
            layers.dir = here('eez/layers'),
            flds_id    = conf$config$layers_id_fields)

## some warnings like this are ok here (check on duplicated rows): 

# Unused fields...
# uninhabited: southern_island,est_population
# ico_spp_iucn_status: iucn_sid,eval_yr
# mar_harvest_tonnes: taxa_group,family

# Layers missing data, ie all NA ...
# element_wts_cp_km2_x_protection: element_wts_cp_km2_x_protection.csv
# element_wts_cs_km2_x_storage: element_wts_cs_km2_x_storage.csv
# element_wts_hab_pres_abs: element_wts_hab_pres_abs.csv

# Rows duplicated...
# ss_spi: 660
# res_spi: 660
# ico_spp_iucn_status: 15776
# mar_sustainability_score: 1

# calculate scores for each year scenario and save to a single csv file:

## General function to calculate scores
get_scores <- function(s_year){  #s_year=2020

  #s_year <- as.numeric(s_year)
  print(sprintf("For assessment year %s", s_year))

  # set the scenario year
  layers$data$scenario_year <-  s_year

  # clear out the file that keeps track of reference points for each scenario year

  if(file.exists(sprintf(here('eez/temp/reference_pts_%s.csv'), s_year)))
  {file.remove(sprintf(here('eez/temp/reference_pts_%s.csv'), s_year))}

  ref_pts <- data.frame(year   = as.integer(),
                        goal   = as.character(),
                        method = as.character(),
                        reference_point = as.character())
  write_csv(ref_pts, sprintf(here('eez/temp/reference_pts_%s.csv'), s_year))


  # calculate scores
  scores_sy <- ohicore::CalculateAll(conf, layers) %>%
    dplyr::mutate(year = s_year)

}

## Apply function
### set up conf and layer objects
conf   <-  ohicore::Conf(here('eez/conf'))
layers <-  ohicore::Layers(layers.csv = here('eez/layers.csv'), layers.dir = here('eez/layers'))

#scorelist = lapply(X=2018, FUN=get_scores)
scorelist = lapply(X=scenario_years, FUN=get_scores) # 27 warnings were generated (nothing of concern)
scores_all_years <- dplyr::bind_rows(scorelist)


# save results
write.csv(scores_all_years, here('eez/scores.csv'), na='', row.names=F)
```

### Step 10

Review results

- **Change file name to your data layer!!**

- Look for the output file in `eez/score_check/<your_file_name>_score_check.html`

```{r eval = FALSE}
### Some methods for visualizing the data
### final commit from last year (v2021): af4b1f3baf55704f272738d900560fb92cb81ab1
### Link being sourced here is incorrect, need to change it! ????? <- v2022

ohicore::score_check(
  
  file_name = "fp_weight", 
  
  commit = "previous", 
  scenario_year = current_year,
  save_csv = TRUE, NA_compare = TRUE
)
```

**Below here is case-to-case basis.**

```{r eval = FALSE}
compare <- read.csv(here("eez/score_check/fis_saup_update_diff_data_2021-09-02.csv"))

fis_test <- compare %>%
  dplyr::filter(goal == "FIS",
         year == 2021, 
         dimension == "score")

test <- scores_all_years %>%
  dplyr::filter(dimension == "status") %>%
  dplyr::filter(goal == "FIS") %>%
  dplyr::filter(region_id == 146)
  
test_pit <- read.csv("https://raw.githubusercontent.com/OHI-Science/ohiprep_v2021/gh-pages/globalprep/fis/v2021/output/mean_catch_minus_feed.csv") %>%
  dplyr::filter(rgn_id == 146) %>%
  dplyr::group_by(year) %>%
  dplyr::summarise(tons = sum(mean_catch))

test_pit_old <- read.csv("https://raw.githubusercontent.com/OHI-Science/ohiprep_v2021/gh-pages/globalprep/fis/v2021_old/output/mean_catch_minus_feed.csv") %>%
  dplyr::filter(rgn_id == 146) %>%
  dplyr::group_by(year) %>%
  dplyr::summarise(tons = sum(mean_catch))

## significantly more catch is reported for Pitcairn in the SAUP data than in the Watson data


p <- ggplot(dplyr::filter(compare, year==2018 & dimension=="status" & goal == "FIS"), aes(x=old_score, y=score)) +
  geom_point(aes(text = paste0("rgn = ", rgn_name)), shape=19) +
  geom_abline(slope=1, intercept=0) +
  labs(x="catch weighting", y="no catch weighting") + 
  theme_bw()

plotly_fig <- plotly::ggplotly(p)
htmlwidgets::saveWidget(plotly::as_widget(plotly_fig), "tmp_file.html", 
                        selfcontained = TRUE)


dplyr::filter(compare, is.na(old_score) & !is.na(score))


# looking within a goal:
source("../../ohiprep_v2018/src/R/VisGlobal.R")
scatterPlot(repo="ohi-global", scenario="eez", commit="e0ed46b", filter_year=2017,
            goal="FIS", dim="status", fileSave="FIS_old_new_compare")

goalHistogram(scenario="eez2016", goal="AO", dim="status", fileSave="AO_need_eez2016")
```

### Step 11: Summarize results in an issue to update team members!

### Step 12: Update metadata files

